{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import import_ipynb\n",
    "#import numpy.linalg as LA\n",
    "#import LMM as lmm\n",
    "import random\n",
    "import time\n",
    "import os\n",
    "import pandas as pd\n",
    "from scipy.io import mmread\n",
    "import scipy.sparse as sp\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import Image\n",
    "import scanpy as sc\n",
    "import matplotlib.pyplot as plt\n",
    "import statsmodels.api as sm\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.pipeline import Pipeline\n",
    "import matplotlib.patches as mpatches\n",
    "from statsmodels.graphics.api import abline_plot\n",
    "import seaborn as sns\n",
    "import umap\n",
    "from numpy import eye, asarray, dot, sum, diag\n",
    "from numpy.linalg import svd\n",
    "\n",
    "import statsmodels.formula.api as smf\n",
    "import pandas\n",
    "\n",
    "\n",
    "np.random.seed(10)\n",
    "\n",
    "def get_binary_covariate(covariate, covariate_level, data):\n",
    "    covariate_list = np.zeros((data.obs.shape[0]))\n",
    "    for i in range(data.obs.shape[0]):\n",
    "        ### select the ith element of \n",
    "        if data.obs[[covariate]].squeeze()[i] == covariate_level:\n",
    "            covariate_list[i] = 1\n",
    "    return covariate_list\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def varimax(Phi, gamma = 1.0, q = 100, tol = 1e-6):\n",
    "    p,k = Phi.shape\n",
    "    R = eye(k)\n",
    "    d=0\n",
    "    for i in range(q):\n",
    "        d_old = d\n",
    "        Lambda = dot(Phi, R)\n",
    "        u,s,vh = svd(dot(Phi.T,asarray(Lambda)**3 - (gamma/p) * dot(Lambda, diag(diag(dot(Lambda.T,Lambda))))))\n",
    "        R = dot(u,vh)\n",
    "        d = sum(s)\n",
    "        if d_old!=0 and d/d_old < 1 + tol: break\n",
    "    Lambda = dot(Phi, R)\n",
    "\n",
    "    return {'rotloadings':Lambda, 'rotmat':R}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                          orig.ident  nCount_RNA  nFeature_RNA sample strain  \\\n",
      "DA_01_AAACCTGAGACTTGAA-1           0      3007.0          1244  DA_01     DA   \n",
      "DA_01_AAACCTGAGCCATCGC-1           0      2176.0           919  DA_01     DA   \n",
      "DA_01_AAACCTGAGGGAAACA-1           0      1978.0           829  DA_01     DA   \n",
      "DA_01_AAACCTGCACCCATTC-1           0      2702.0          1104  DA_01     DA   \n",
      "DA_01_AAACCTGCATGCATGT-1           0      2664.0          1061  DA_01     DA   \n",
      "\n",
      "                         cluster           refined_cell_ID  \n",
      "DA_01_AAACCTGAGACTTGAA-1       5  DA_01_AAACCTGAGACTTGAA-1  \n",
      "DA_01_AAACCTGAGCCATCGC-1       9  DA_01_AAACCTGAGCCATCGC-1  \n",
      "DA_01_AAACCTGAGGGAAACA-1       2  DA_01_AAACCTGAGGGAAACA-1  \n",
      "DA_01_AAACCTGCACCCATTC-1      11  DA_01_AAACCTGCACCCATTC-1  \n",
      "DA_01_AAACCTGCATGCATGT-1       5  DA_01_AAACCTGCATGCATGT-1  \n"
     ]
    }
   ],
   "source": [
    "#### import the immune subpopulation of the rat samples\n",
    "data = sc.read('/home/delaram/scLMM/input_data_designMat/inputdata_rat_set1_countData_2.h5ad') ## attributes removed\n",
    "data.var_names_make_unique()\n",
    "# a.obs['orig.ident'].head()\n",
    "### renaming the meta info column names: https://github.com/theislab/scvelo/issues/255\n",
    "data.__dict__['_raw'].__dict__['_var'] = data.__dict__['_raw'].__dict__['_var'].rename(columns={'_index': 'features'})\n",
    "\n",
    "data_numpy = data.X.toarray()\n",
    "cell_sums = np.sum(data_numpy,axis=1) # row sums - library size\n",
    "gene_sums = np.sum(data_numpy,axis=0) # col sums - sum reads in a gene\n",
    "gene_vars = np.var(data_numpy, axis=0)\n",
    "data_numpy = data_numpy[:,gene_sums != 0]\n",
    "\n",
    "### print head pf the data.obs\n",
    "print(data.obs.head())\n",
    "data_sub = data_numpy\n",
    "strain = data.obs.strain\n",
    "#### sample metadata\n",
    "y_cluster =data.obs.cluster \n",
    "y_sample = data.obs.sample\n",
    "y_sample = data.obs[['sample']].squeeze()\n",
    "y_strain_str = data.obs[['strain']].squeeze()\n",
    "\n",
    "y_strain = get_binary_covariate('strain', 'DA', data=data)\n",
    "\n",
    "\n",
    "## working with the rat data\n",
    "num_cells = data_sub.shape[0]\n",
    "num_genes = data_sub.shape[1]\n",
    "num_genes = 5000\n",
    "\n",
    "#### select num_genes genes based on variance\n",
    "### calculate the variance for each gene\n",
    "gene_vars = np.var(data_numpy, axis=0)\n",
    "### select the top num_genes genes with the highest variance\n",
    "gene_idx = np.argsort(gene_vars)[::-1][0:num_genes]\n",
    "### subset the data matrix to the top num_genes genes\n",
    "data_numpy = data_numpy[:, gene_idx]\n",
    "\n",
    "#### randomly select num_genes genes\n",
    "#gene_idx = random.sample(range(0, data_numpy.shape[1]), num_genes)\n",
    "#data_numpy = data_numpy[:, gene_idx]\n",
    "\n",
    "y = data_numpy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### generating the binary sample info for design matrix\n",
    "y_DA_01 = get_binary_covariate('sample', 'DA_01', data=data)\n",
    "y_DA_02 = get_binary_covariate('sample', 'DA_02', data=data)\n",
    "y_LEW_01 = get_binary_covariate('sample', 'LEW_01', data=data)\n",
    "y_LEW_02 = get_binary_covariate('sample', 'LEW_02', data=data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17\n",
      "17\n",
      "[4989 4212 2606 2091 1740 1150 1124  984  977  713  518  517  446  410\n",
      "  265  167  127]\n"
     ]
    }
   ],
   "source": [
    "# create a one hot encoded array of the y_cluster\n",
    "y_cluster_int = np.array(y_cluster, dtype=int) ## convert the y_cluster to a numpy array of integers\n",
    "encoded_array = np.zeros((y_cluster_int.size, y_cluster_int.max()+1), dtype=int) #creating a 2D array filled with 0's\n",
    "encoded_array[np.arange(y_cluster_int.size),y_cluster_int] = 1  #replacing 0 with a 1 at the index of the original array\n",
    "\n",
    "## calculate the column sums of the encoded array\n",
    "col_sums = np.sum(encoded_array, axis=0)\n",
    "## get the number of unique clusters in y_cluster\n",
    "num_clusters = len(np.unique(y_cluster))\n",
    "\n",
    "print(num_clusters)\n",
    "print(len(col_sums)) ## should be equal to the number of unique clusters\n",
    "print(col_sums)\n",
    "\n",
    "## remove the last column of the encoded array - x needs to be full rank\n",
    "encoded_array = encoded_array[:,0:num_clusters-1] # why isn't this needed????"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Design matrix : Intercept + Depth\n",
    "x = np.column_stack((np.ones((data.obs.shape[0],1)), data.obs.nCount_RNA))\n",
    "print(x[0:3,:])\n",
    "print(x.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Design matrix : Intercept + sample\n",
    "x = np.column_stack((y_DA_01, y_DA_02, y_LEW_01, y_LEW_02))\n",
    "x = sm.add_constant(x) ## adding the intercept\n",
    "print(x[0:3,:])\n",
    "print(x.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Design matrix : Intercept + Depth + sample\n",
    "x = np.column_stack((y_DA_01, y_DA_02, y_LEW_01, y_LEW_02))\n",
    "x = np.column_stack((x, data.obs.nCount_RNA))\n",
    "x = sm.add_constant(x) ## adding the intercept\n",
    "\n",
    "print(x[0:3,:])\n",
    "print(x.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Design matrix : Intercept + Depth + cell-types\n",
    "x = np.column_stack((np.ones((data.obs.shape[0],1)), data.obs.nCount_RNA, encoded_array))\n",
    "print(x[0:3,:])\n",
    "print(x.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Design matrix : Intercept + Depth + cell-types + strain\n",
    "x = np.column_stack((np.ones((data.obs.shape[0],1)), data.obs.nCount_RNA, encoded_array + y_strain))\n",
    "print(x[0:3,:])\n",
    "print(x.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.000e+00 3.007e+03 0.000e+00 0.000e+00 0.000e+00 0.000e+00 0.000e+00\n",
      "  1.000e+00 0.000e+00 0.000e+00 0.000e+00 0.000e+00 0.000e+00 0.000e+00\n",
      "  0.000e+00 0.000e+00 0.000e+00 0.000e+00 0.000e+00 1.000e+00 0.000e+00\n",
      "  0.000e+00 0.000e+00]\n",
      " [1.000e+00 2.176e+03 0.000e+00 0.000e+00 0.000e+00 0.000e+00 0.000e+00\n",
      "  0.000e+00 0.000e+00 0.000e+00 0.000e+00 1.000e+00 0.000e+00 0.000e+00\n",
      "  0.000e+00 0.000e+00 0.000e+00 0.000e+00 0.000e+00 1.000e+00 0.000e+00\n",
      "  0.000e+00 0.000e+00]\n",
      " [1.000e+00 1.978e+03 0.000e+00 0.000e+00 1.000e+00 0.000e+00 0.000e+00\n",
      "  0.000e+00 0.000e+00 0.000e+00 0.000e+00 0.000e+00 0.000e+00 0.000e+00\n",
      "  0.000e+00 0.000e+00 0.000e+00 0.000e+00 0.000e+00 1.000e+00 0.000e+00\n",
      "  0.000e+00 0.000e+00]]\n",
      "(23036, 23)\n"
     ]
    }
   ],
   "source": [
    "#### Design matrix : Intercept + Depth + cell-types + sample\n",
    "x = np.column_stack((np.ones((data.obs.shape[0],1)), data.obs.nCount_RNA, encoded_array , y_DA_01, y_DA_02, y_LEW_01, y_LEW_02))\n",
    "print(x[0:3,:])\n",
    "print(x.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Design matrix : Intercept + Depth + cell-types + sample + strain\n",
    "### including sample as well as cluster as covariates\n",
    "x = np.column_stack((np.ones((data.obs.shape[0],1)), data.obs.nCount_RNA, encoded_array, y_DA_01, y_DA_02, y_LEW_01, y_LEW_02, y_strain))\n",
    "print(x[0:3,:])\n",
    "print(x.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(23036, 23)\n",
      "(23036, 5000)\n"
     ]
    }
   ],
   "source": [
    "#### Interaction terms\n",
    "data = sm.datasets.scotland.load(as_pandas=True)\n",
    "df = data.data\n",
    "\n",
    "gamma_model = smf.glm(formula='YES ~ COUTAX + UNEMPF + COUTAX:UNEMPF + MOR',\n",
    "data=df, family=sm.families.Gamma())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time to fit the model:  204.0016176700592\n"
     ]
    }
   ],
   "source": [
    "### fit a poisson regression model to each gene and save the results\n",
    "\n",
    "num_vars = x.shape[1]\n",
    "\n",
    "### make an empty array to store the p-values and coefficients\n",
    "pvalue = []\n",
    "coefficient = []\n",
    "yhat = []\n",
    "tvalues = []\n",
    "resid_pearson = []\n",
    "resid_deviance = []\n",
    "resid_response = []\n",
    "resid_working = []\n",
    "fittedvalues = []\n",
    "nobs = []\n",
    "models = []\n",
    "\n",
    "pearson_chi2 = []\n",
    "deviance = []\n",
    "null_deviance = []\n",
    "\n",
    "### time the fitting process\n",
    "start_time = time.time()\n",
    "\n",
    "for i in range(len(y[0])):\n",
    "    y_a_gene = y[:, i]\n",
    "    model = sm.GLM(y_a_gene, x, family=sm.families.Poisson())\n",
    "    result = model.fit()\n",
    "    #print(result.summary())\n",
    "    \n",
    "    #models.append([result])\n",
    "    #coefficient.append([result.params])\n",
    "    #pvalue.append([result.pvalues]) ## yhat == fittedvalue == mu\n",
    "    #yhat.append([result.predict()])\n",
    "    #fittedvalues.append([result.fittedvalues])\n",
    "\n",
    "    #nobs.append([result.nobs])\n",
    "    #tvalues.append([result.tvalues])\n",
    "    resid_pearson.append([result.resid_pearson])\n",
    "    resid_deviance.append([result.resid_deviance])\n",
    "    resid_response.append([result.resid_response])\n",
    "    #resid_working.append([result.resid_working])\n",
    "    \n",
    "    #pearson_chi2.append([result.pearson_chi2])\n",
    "    #deviance.append([result.deviance])\n",
    "    #null_deviance.append([result.null_deviance])\n",
    "\n",
    "end_time = time.time()\n",
    "print('time to fit the model: ', end_time - start_time)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "pvalue = np.asarray(pvalue).reshape(num_genes, num_vars)\n",
    "coefficient = np.asarray(coefficient).reshape(num_genes, num_vars)\n",
    "tvalues = np.asarray(tvalues).reshape(num_genes, num_vars)\n",
    "#### print the head of the pvalues\n",
    "print(pvalue[0:5, :])\n",
    "\n",
    "yhat = np.asarray(yhat).reshape(num_genes, num_cells)\n",
    "fittedvalues = np.asarray(fittedvalues).reshape(num_genes, num_cells)\n",
    "resid_pearson = np.asarray(resid_pearson).reshape(num_genes, num_cells)\n",
    "resid_deviance = np.asarray(resid_deviance).reshape(num_genes, num_cells)\n",
    "resid_response = np.asarray(resid_response).reshape(num_genes, num_cells)\n",
    "resid_working = np.asarray(resid_working).reshape(num_genes, num_cells)\n",
    "nobs = np.asarray(nobs).reshape(num_genes, 1)\n",
    "\n",
    "pearson_chi2 = np.asarray(pearson_chi2).reshape(num_genes, 1)\n",
    "deviance = np.asarray(deviance).reshape(num_genes, 1)\n",
    "null_deviance = np.asarray(null_deviance).reshape(num_genes, 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "resid_pearson = np.asarray(resid_pearson).reshape(num_genes, num_cells)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### chosing a random gene to plot\n",
    "i = 800 ## gene index\n",
    "result = models[i][0] \n",
    "fittedvalues_i = fittedvalues[i]\n",
    "y_i = y[:, i]\n",
    "\n",
    "### get the summary of the model\n",
    "print(result.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### diagnostic plots of the model outputs\n",
    "plt.rcParams.update({'font.size': 10})\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "ax.scatter(fittedvalues_i, y[:, i])\n",
    "line_fit = sm.OLS(y_i, sm.add_constant(fittedvalues_i, prepend=True)).fit()\n",
    "abline_plot(model_results=line_fit, ax=ax, alpha=0.5)\n",
    "\n",
    "ax.set_title('Model Fit Plot')\n",
    "ax.set_ylabel('Observed values')\n",
    "ax.set_xlabel('Fitted values')\n",
    "\n",
    "sns.jointplot(fittedvalues_i, y[:, i], kind='scatter', stat_func=None, color='b', height=4)\n",
    "sns.set_context(font_scale=0.9)                                                  \n",
    "plt.title('Model Fit Plot')\n",
    "plt.xlabel('Fitted values')\n",
    "plt.ylabel('Observed values')\n",
    "## change the size of the text in plot\n",
    "plt.rc('font', size=10)\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "resid_pearson_i = resid_pearson[i]\n",
    "ax.scatter(fittedvalues_i, resid_pearson_i, alpha=0.1)\n",
    "#ax.hlines(0, 0, 7)\n",
    "#ax.set_xlim(0, 7)\n",
    "ax.set_title('Residual Dependence Plot')\n",
    "ax.set_ylabel('Pearson Residuals')\n",
    "ax.set_xlabel('Fitted values')\n",
    "\n",
    "sns.jointplot(fittedvalues_i, resid_pearson_i, kind='scatter', stat_func=None, color='b', height=4)\n",
    "sns.set_context(font_scale=0.9)                                                  \n",
    "plt.title('Model Fit Plot')\n",
    "plt.xlabel('Fitted values')\n",
    "plt.ylabel('Pearson Residuals')\n",
    "## change the size of the text in plot\n",
    "plt.rc('font', size=10)\n",
    "plt.show()\n",
    "\n",
    "from scipy import stats\n",
    "fig, ax = plt.subplots()\n",
    "resid = resid_deviance[i]\n",
    "resid_std = stats.zscore(resid)\n",
    "ax.hist(resid_std, bins=25)\n",
    "ax.set_title('Histogram of standardized deviance residuals')\n",
    "\n",
    "from statsmodels import graphics\n",
    "graphics.gofplots.qqplot(resid, line='r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### calculate the goodness of fit of GLM model\n",
    "# https://www.statsmodels.org/stable/generated/statsmodels.genmod.generalized_linear_model.GLMResults.html#statsmodels.genmod.generalized_linear_model.GLMResults\n",
    "\n",
    "### statsmodels GLM source code:\n",
    "# https://github.com/statsmodels/statsmodels/blob/main/statsmodels/genmod/families/links.py\n",
    "\n",
    "### poisson family link function\n",
    "# https://github.com/statsmodels/statsmodels/blob/main/statsmodels/genmod/families/family.py\n",
    "\n",
    "\n",
    "print('log-likelihood of the model: ', result.llf)\n",
    "\n",
    "### calculate the null deviance manually - float\n",
    "# NullDeviance = 2*(LL(SaturatedModel)−LL(NullModel))\n",
    "# The value of the deviance function for the model fit with a constant as the only regressor\n",
    "# GLMResults.llf: Value of the loglikelihood function evalued at params. See statsmodels.families.family for distribution-specific loglikelihoods.\n",
    "null_deivance_i = 2*(result.llnull - result.llf)\n",
    "print('null deviance manual calculation: ', null_deivance_i) ## why the result is different from the result.null_deviance?\n",
    "print('null deviance: ',result.null_deviance)\n",
    "\n",
    "\n",
    "### calculate the deviance - float\n",
    "# The value of the deviance function for the model fit with the full set of regressors\n",
    "# ResidualDeviance = 2*(LL(SaturatedModel)−LL(ProposedModel))\n",
    "deviance_i =result.deviance \n",
    "print('deviance: ', deviance_i)\n",
    "\n",
    "\n",
    "### Response residual - array\n",
    "# The response residuals are defined as endog - fittedvalues\n",
    "response_residual_i = y_i - fittedvalues_i\n",
    "print('response residual manual: ', response_residual_i[:3])\n",
    "print('response residual is: ', resid_response[i][:3])\n",
    "\n",
    "### Deviance residual - how is this calculated? - array\n",
    "print('residual deviance is: ', resid_deviance[i][1:3])\n",
    "\n",
    "  \n",
    "## Working residual - response residuals scaled by the derivative of the inverse of the link function\n",
    "# The working residuals are defined as resid_response/link’(mu)\n",
    "# mu: The inverse of the link function at the linear predicted values. - then why is mu=yhat instead of mu=e^yhat? \n",
    "# https://www.statsmodels.org/dev/glm.html#link-functions\n",
    "resid_working_i = resid_response[i]/result.family.link.deriv(result.mu) ## derivatives of the link function\n",
    "print('working residual manual: ', resid_working_i[:3])\n",
    "print('working residual is: ', resid_working[i][:3])\n",
    "\n",
    "\n",
    "### The Pearson residuals - response residuals scaled by the square root of the variance function\n",
    "# (endog - mu)/sqrt(VAR(mu)) where VAR is the distribution specific variance function\n",
    "resid_pearson_i = (y_i - result.mu)/np.sqrt(result.family.variance(result.mu)) ## variance function of the poisson family is power?\n",
    "print('pearson residual manual: ', resid_pearson_i[:3])\n",
    "print('pearson residual is: ', resid_pearson[i][:3])\n",
    "\n",
    "\n",
    "### calculate the Pearson’s Chi-Squared statistic \n",
    "# the sum of the squares of the Pearson residuals.\n",
    "Pearson_Chi_Squared_i = sum(resid_pearson[i]**2)\n",
    "print('Pearson_Chi_Squared manual: ', Pearson_Chi_Squared_i)\n",
    "print('Pearson_Chi_Squared: ', result.pearson_chi2)\n",
    "\n",
    "\n",
    "### calculate the BIC - float\n",
    "# BIC : deviance - df_resid * log(nobs)\n",
    "BIC_i = deviance_i - result.df_resid * np.log(nobs[0])\n",
    "print('BIC manual: ', BIC_i)\n",
    "print('BIC is: ', result.bic)\n",
    "\n",
    "\n",
    "### calculate the AIC - float\n",
    "# AIC: aike Information Criterion\n",
    "# -2 * llf + 2 * (df_model + 1)\n",
    "## df_model: rank of the regression matrix excluding the intercept:  df_model = k_exog - 1 = 0 is only strain is included\n",
    "AIC_i = deviance_i + 2 * (result.df_model + 1)\n",
    "AIC_i = -2 * result.llf + 2 * (result.df_model + 1)\n",
    "print('AIC manual: ', AIC_i)\n",
    "print('AIC is: ', result.aic)\n",
    "\n",
    "\n",
    "### calculate the pseudo R-squared - float\n",
    "pseudo_rsquared_i = 1 - abs(result.deviance/result.null_deviance)\n",
    "print('pseudo R-squared manual: ', pseudo_rsquared_i)\n",
    "#print('pseudo R-squared is: ', result.pseudo_rsquared)\n",
    "\n",
    "### calculate the Wald test - float\n",
    "# result.wald_test('x1 = x2 = 0')\n",
    "\n",
    "# GLMResults.wald_test : Compute a Wald-test for a joint linear hypothesis.\n",
    "# GLMResults.compare_lr_test : Likelihood ratio test for comparing two models.\\n\"\n",
    "\n",
    "print(resid_response.T.shape)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_pca(pca_scores, pca, num_components_to_plot, title='PCA of the data matrix'):\n",
    "    \n",
    "    for i in range(1, num_components_to_plot):\n",
    "        ## color PCA based on strain\n",
    "        plt.figure()\n",
    "        plt.scatter(pca_scores[:,0], pca_scores[:,i], c=strain_color, s=1) \n",
    "        plt.xlabel('PC1')\n",
    "        plt.ylabel('PC'+str(i+1))\n",
    "        plt.title(title)\n",
    "        plt.legend(handles=[mpatches.Patch(color='springgreen', label='LEW'),\n",
    "                            mpatches.Patch(color='hotpink', label='DA')])\n",
    "        plt.show()\n",
    "\n",
    "        ## color PCA based on cluster\n",
    "        plt.figure()\n",
    "        plt.scatter(pca_scores[:,0], pca_scores[:,i], c=c, s=1)\n",
    "        plt.xlabel('PC1')\n",
    "        plt.ylabel('PC'+str(i+1))\n",
    "        plt.title(title)\n",
    "        plt.show()\n",
    "\n",
    "        ###  ## color PCA based on sample\n",
    "        plt.figure()\n",
    "        plt.scatter(pca_scores[:,0], pca_scores[:,i], c=sample_color, s=1)\n",
    "        plt.xlabel('PC1')\n",
    "        plt.ylabel('PC'+str(i+1))\n",
    "        plt.legend(handles=[mpatches.Patch(color='palegreen', label='LEW_01'),\n",
    "                            mpatches.Patch(color='forestgreen', label='LEW_02'),\n",
    "                            mpatches.Patch(color='pink', label='DA_01'),\n",
    "                            mpatches.Patch(color='orchid', label='DA_02')], loc='best')\n",
    "        plt.show()\n",
    "\n",
    "\n",
    "    # plot the variance explained by each PC\n",
    "    plt.figure()\n",
    "    plt.plot(pca.explained_variance_ratio_)\n",
    "    plt.title('Variance explained by each PC')\n",
    "    plt.xlabel('PC')\n",
    "    plt.ylabel('Variance explained')\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def plot_umap(pca_scores, pca , title='UMAP of the PC components of the gene expression matrix'):\n",
    "\n",
    "    ### apply UMAP to teh PCA components\n",
    "    reducer = umap.UMAP()\n",
    "    embedding = reducer.fit_transform(pca_scores)\n",
    "    print('embedding shape: ', embedding.shape)\n",
    "    \n",
    "    ### plot the UMAP embedding\n",
    "    plt.figure()\n",
    "    plt.scatter(embedding[:, 0], embedding[:, 1], c=strain_color, s=1)\n",
    "    plt.title(title)\n",
    "    plt.legend(handles=[mpatches.Patch(color='springgreen', label='LEW'),\n",
    "                        mpatches.Patch(color='hotpink', label='DA')])\n",
    "    plt.show()\n",
    "\n",
    "    plt.figure()\n",
    "    plt.scatter(embedding[:, 0], embedding[:, 1], c=sample_color, s=1)\n",
    "    plt.title(title)\n",
    "    plt.legend(handles=[mpatches.Patch(color='palegreen', label='LEW_01'),\n",
    "            mpatches.Patch(color='forestgreen', label='LEW_02'),\n",
    "            mpatches.Patch(color='pink', label='DA_01'),\n",
    "            mpatches.Patch(color='orchid', label='DA_02')], loc='best')\n",
    "    plt.show()\n",
    "\n",
    "    plt.figure()\n",
    "    plt.scatter(embedding[:, 0], embedding[:, 1], c=c, s=1)\n",
    "    plt.title(title)\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "\n",
    "#### generating the list of colors for clusters\n",
    "colors = plt.cm.rainbow(np.linspace(0, 1, len(set(y_cluster)))) ### set the color for each cluster\n",
    "my_color = {}\n",
    "### define a dictionary to map the cluster number to the color\n",
    "list_levels = list(set(y_cluster))\n",
    "for i in range(len(set(list_levels))):\n",
    "    my_color[list_levels[i]] = colors[i]\n",
    "### generate a list containing the corresponding color for each cluster\n",
    "c = [my_color[y_cluster[i]] for i in range(len(y_cluster))]\n",
    "\n",
    "\n",
    "### generating the list of colors for samples\n",
    "my_color = {'LEW_01': 'palegreen', 'LEW_02':'forestgreen', 'DA_01':'pink', 'DA_02':'orchid'}\n",
    "### generate a list containing the corresponding color for each sample\n",
    "sample_color = [my_color[y_sample[i]] for i in range(len(y_sample))]\n",
    "\n",
    "my_color = {'LEW': 'springgreen', 'DA':'hotpink'}\n",
    "strain_color = [my_color[y_strain_str[i]] for i in range(len(y_strain_str))]\n",
    "\n",
    "### applying PCA to the data matrix\n",
    "num_components = 30\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(y.shape)\n",
    "num_components = 30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### using pipeline to scale the data first\n",
    "pipeline = Pipeline([('scaling', StandardScaler()), ('pca', PCA(n_components=num_components))])\n",
    "pca_scores = pipeline.fit_transform(y)\n",
    "pca = pipeline.named_steps['pca']\n",
    "pca_loading = pca.components_\n",
    "\n",
    "plot_pca(pca_scores, pca, 5, title='PCA of data')\n",
    "plot_umap(pca_scores, pca, title='UMAP of the PC components of the data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### First implementation of Varimax rotation ####\n",
    "## method: scale(original pc scores) %*% rotmat\n",
    "\n",
    "## apply varimax rotation to the loadings\n",
    "varimax_rot = varimax(pca_loading.T)\n",
    "loadings_rot = varimax_rot['rotloadings']\n",
    "rotmat = varimax_rot['rotmat']\n",
    "pca_scores_rot = dot(pca_scores, rotmat)\n",
    "\n",
    "print('loadings_rot shape: ', loadings_rot.shape)\n",
    "print('rotmat shape: ', rotmat.shape)\n",
    "print('pca_scores shape: ', pca_scores.shape)\n",
    "print('pca_scores_rot shape: ', pca_scores_rot.shape)\n",
    "\n",
    "\n",
    "plot_pca(pca_scores_rot, pca, 10, title='PCA of varimax rotated pearson residuals')\n",
    "plot_umap(pca_scores_rot, pca, title='UMAP of the varimax-PCs on pearson residuals')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### Second implementation of Varimax rotation ####\n",
    "# method: scale(original data) %*% rotatedLoadings\n",
    "\n",
    "## apply varimax rotation to the loadings\n",
    "#loadings_rot shape:  (2000, 10)\n",
    "y_std = StandardScaler().fit_transform(y)\n",
    "pca_scores_rot_2 = dot(y_std, loadings_rot)\n",
    "\n",
    "### plot the rotated scores pca_scores_rot\n",
    "plot_pca(pca_scores_rot_2, pca, 10, title='PCA of response residuals after varimax rotation')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## visualize the loadings\n",
    "plt.figure()\n",
    "plt.imshow(loadings_rot, cmap=\"RdBu_r\", vmin=-1, vmax=1)\n",
    "plt.colorbar().ax.set_ylabel(\"$\\\\beta$\", rotation=0)\n",
    "plt.xticks([0, 1], [\"PC1\", \"PC2\"])\n",
    "plt.title(\"PCA loadings (varimax rotated)\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### applying PCA to the response residuals\n",
    "pipeline = Pipeline([('scaling', StandardScaler()), ('pca', PCA(n_components=num_components))])\n",
    "pca_scores = pipeline.fit_transform(resid_response.T)\n",
    "pca = pipeline.named_steps['pca']\n",
    "pca_loading = pca.components_\n",
    "\n",
    "#print('explained variance ratio: ', pca.explained_variance_ratio_)\n",
    "#print('singular values: ', pca.singular_values_)#\n",
    "print('noise_variance: ', pca.noise_variance_)\n",
    "\n",
    "plot_pca(pca_scores, pca, 2, title='PCA of response residuals')\n",
    "plot_umap(pca_scores, pca, title='UMAP of the PC components of the response residuals')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "noise_variance:  0.9824045621837092\n"
     ]
    }
   ],
   "source": [
    "### applying PCA to the pearson residuals\n",
    "\n",
    "pipeline = Pipeline([('scaling', StandardScaler()), ('pca', PCA(n_components=num_components))])\n",
    "pca_scores = pipeline.fit_transform(resid_pearson.T)\n",
    "pca = pipeline.named_steps['pca']\n",
    "pca_loading = pca.components_\n",
    "\n",
    "#print('explained variance ratio: ', pca.explained_variance_ratio_)\n",
    "#print('singular values: ', pca.singular_values_)#\n",
    "print('noise_variance: ', pca.noise_variance_)\n",
    "\n",
    "plot_pca(pca_scores, pca, 15, title='PCA of pearson residuals')\n",
    "plot_umap(pca_scores, pca, title='UMAP of the PC components of the pearson residuals')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### First implementation of Varimax rotation ####\n",
    "## method: scale(original pc scores) %*% rotmat\n",
    "\n",
    "## apply varimax rotation to the loadings\n",
    "varimax_rot = varimax(pca_loading.T)\n",
    "loadings_rot = varimax_rot['rotloadings']\n",
    "rotmat = varimax_rot['rotmat']\n",
    "pca_scores_rot = dot(pca_scores, rotmat)\n",
    "\n",
    "print('loadings_rot shape: ', loadings_rot.shape)\n",
    "print('rotmat shape: ', rotmat.shape)\n",
    "print('pca_scores shape: ', pca_scores.shape)\n",
    "print('pca_scores_rot shape: ', pca_scores_rot.shape)\n",
    "\n",
    "\n",
    "### plot the rotated scores pca_scores_rot\n",
    "plot_pca(pca_scores_rot, pca, 30, title='PCA of pearson residuals after varimax rotation')\n",
    "plot_umap(pca_scores, pca, title='UMAP of varimax-PCA on pearson residuals')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### get the UMAP cooridates for each data point from the embedding\n",
    "### get the head of the embedding\n",
    "embedding[:len(y_sample), :]\n",
    "### add cluster information to the embedding\n",
    "embedding = np.concatenate((embedding, y_cluster_int.reshape(-1, 1)), axis=1)\n",
    "### print head of the embedding\n",
    "print(embedding[:len(y_sample), :])\n",
    "\n",
    "x_coord = 12.5\n",
    "y_coord = 2\n",
    "### subset embedding to get the coordinates od data bellow  -4 in y axis and below 0 in x axis\n",
    "embedding_sub = embedding[(embedding[:, 1] < y_coord) & (embedding[:, 0] > x_coord), :]\n",
    "\n",
    "## get a summary of cluster values in the last column of the embedding\n",
    "print(pd.Series(embedding_sub[:, -1]).value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### applying PCA to the deviance residuals\n",
    "pipeline = Pipeline([('scaling', StandardScaler()), ('pca', PCA(n_components=num_components))])\n",
    "pipeline.fit_transform(resid_deviance)\n",
    "pca = pipeline.named_steps['pca']\n",
    "\n",
    "#pca = PCA(n_components=20)\n",
    "#pca.fit(resid_response)\n",
    "\n",
    "#print('explained variance ratio: ', pca.explained_variance_ratio_)\n",
    "#print('singular values: ', pca.singular_values_)#\n",
    "print('noise_variance: ', pca.noise_variance_)\n",
    "\n",
    "plot_pca(pca, 4, title='PCA of deviance residuals')\n",
    "plot_umap(pca, title='UMAP of the PC components of the deviance residuals')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### convert the pvalue matrix to a pandas dataframe\n",
    "pvalue_pd = pd.DataFrame(pvalue)\n",
    "\n",
    "### check the colnames of data matrix\n",
    "gene_names = data.var_names[gene_sums != 0]\n",
    "gene_names = pd.DataFrame(gene_names[gene_idx])\n",
    "\n",
    "### concatenate the gene names with the pvalues\n",
    "gene_pval_df = pd.concat([gene_names, pvalue_pd], axis=1)\n",
    "column_names = ['gene', 'intercept','strain_DA', 'DA_01', 'LEW_01', 'libsize']\n",
    "# add column_names to the gene_pval_df dataframe\n",
    "gene_pval_df.columns = column_names\n",
    "gene_pval_df.head()\n",
    "### sort the dataframe by strain_DA pvalue\n",
    "gene_pval_df.sort_values(by=['intercept'], inplace=True)\n",
    "gene_pval_df.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### con\n",
    "### convert the coefficient matrix to a pandas dataframe\n",
    "coefficient_pd = pd.DataFrame(coefficient)\n",
    "\n",
    "\n",
    "### concatenate the gene names with the pvalues\n",
    "gene_coeff_df = pd.concat([gene_names, coefficient_pd], axis=1)\n",
    "column_names = ['gene', 'intercept','strain_DA', 'DA_01', 'LEW_01']\n",
    "# add column_names to the gene_pval_df dataframe\n",
    "gene_coeff_df.columns = column_names\n",
    "gene_coeff_df.head()\n",
    "\n",
    "### sort the dataframe by strain_DA coefficient\n",
    "gene_coeff_df.sort_values(by=['DA_01'], inplace=True)\n",
    "gene_coeff_df.head(20)\n",
    "\n",
    "### show the row containing the gene name Itgal\n",
    "gene_name = 'Itgal'\n",
    "gene_coeff_df.loc[gene_coeff_df['gene'] == gene_name]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "c52ec5e6d0c5a1b88e5dee4d34e884e54b43891ef43ae3a37402d55f31b636e1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
