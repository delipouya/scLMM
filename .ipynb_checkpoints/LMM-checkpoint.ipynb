{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LMM was imported successfully.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import numpy.linalg as LA\n",
    "\n",
    "\n",
    "# NOTE:\n",
    "#   Starting values are all calculated based on var y\n",
    "#   Later on we can utilize a smarter intialization\n",
    "\n",
    "\n",
    "\n",
    "### relm ai -> small sample size : div is natural -> 30000 no problem \n",
    " \n",
    "# Original MINQE(U,I) n x n formulation\n",
    "def minqe_unbiased(Kernel, X, y, verbose=True, n_iter=10):\n",
    "    n = Kernel[0].shape[0]\n",
    "    p = len(Kernel)\n",
    "    sig_estimate = np.zeros(p + 1, dtype=np.float64)\n",
    "    sig_estimate[:] = np.var(y, ddof=1) / (p + 1)\n",
    "    iteration_estimate = []\n",
    "    # Convergence\n",
    "    exit_code = 1\n",
    "\n",
    "    for i in range(n_iter):\n",
    "        prev_sig = sig_estimate.copy()\n",
    "\n",
    "        V = sig_estimate[p] * np.eye(n, dtype=np.float64)  # for I\n",
    "        for j in range(p):\n",
    "            V += sig_estimate[j] * Kernel[j]\n",
    "        # print(\"\\t\\tInverting covariance matrix\", flush=True)\n",
    "        V_inv = LA.inv(V)\n",
    "        R = V_inv - V_inv.dot(X).dot(LA.inv(X.T.dot(V_inv).dot(X))).dot(X.T).dot(V_inv)\n",
    "        # print(\"\\t\\tPopulating Infomation mat and Score vec\")\n",
    "        S = np.zeros((p + 1, p + 1), dtype=np.float64)\n",
    "        quad = np.zeros(p + 1, dtype=np.float64)\n",
    "        \n",
    "        ### HH: quadratic approximation until convergence -> naive-> solution: trust region update  \n",
    "        ### makes a constrain -> shrinks the trust region\n",
    "        \n",
    "        for j in range(p):\n",
    "            # print(\"\\t\\t\\tRow: %d of %d\" % (j+1, p), flush=True)\n",
    "            quad[j] = y.T.dot(R).dot(Kernel[j]).dot(R).dot(y)\n",
    "            S[j, p] = np.trace(R.dot(Kernel[j]).dot(R))  # last column\n",
    "            S[p, j] = S[j, p]\n",
    "            for k in range(j, p):\n",
    "                S[j, k] = np.trace(R.dot(Kernel[j]).dot(R).dot(Kernel[k]))\n",
    "                S[k, j] = S[j, k]\n",
    "\n",
    "        S[p, p] = np.trace(R.dot(R))\n",
    "        quad[p] = y.T.dot(R).dot(R).dot(y)\n",
    "        # print(\"\\t\\tScore norm: %.6f, abs_max: %.6f\" % (LA.norm(quad), np.abs(quad).max()) )\n",
    "        # print(\"\\t\\tSolving system linear system\")\n",
    "\n",
    "        sig_estimate = LA.inv(S).dot(quad)\n",
    "        iteration_estimate.append(sig_estimate)\n",
    "\n",
    "        print(\"Quad:\", quad)\n",
    "        print(\"Trace (RKRK):\", S)\n",
    "\n",
    "        if verbose:\n",
    "            print_str = \"\\t MINQE(U,I) vanilla round \" + str(i) + \": \"\n",
    "            for j in range(p + 1):\n",
    "                print_str += \"  {:.4f}\".format(sig_estimate[j])\n",
    "            print(print_str, flush=True)\n",
    "\n",
    "        diff = np.max(np.abs(sig_estimate - prev_sig))\n",
    "        if diff < 1e-4:\n",
    "            exit_code = 0\n",
    "            if verbose:\n",
    "                print(\"\\t Estimates converged, exitting - diff: %.6f\" % (diff))\n",
    "            break\n",
    "\n",
    "    iteration_estimate = np.array(iteration_estimate)\n",
    "    return sig_estimate, iteration_estimate[0, :], iteration_estimate, exit_code\n",
    "\n",
    "\n",
    "# Original MINQE(I) n x n formulation\n",
    "def minqe_biased(Kernel, X, y, verbose=True, n_iter=10):\n",
    "    n = Kernel[0].shape[0]\n",
    "    p = len(Kernel)\n",
    "    sig_estimate = np.zeros(p + 1, dtype=np.float64)\n",
    "    sig_estimate[:] = np.var(y, ddof=1) / (p + 1)\n",
    "    iteration_estimate = []\n",
    "    # Convergence\n",
    "    exit_code = 1\n",
    "\n",
    "    for i in range(n_iter):\n",
    "        prev_sig = sig_estimate.copy()\n",
    "\n",
    "        V = sig_estimate[p] * np.eye(n, dtype=np.float64)  # for I\n",
    "        for j in range(p):\n",
    "            V += sig_estimate[j] * Kernel[j]\n",
    "\n",
    "        V_inv = LA.inv(V)\n",
    "        R = V_inv - V_inv.dot(X).dot(LA.inv(X.T.dot(V_inv).dot(X))).dot(X.T).dot(V_inv)\n",
    "\n",
    "        S = np.zeros((p + 1, p + 1), dtype=np.float64)\n",
    "        sigma = np.zeros(p + 1, dtype=np.float64)\n",
    "        for j in range(p):\n",
    "            sigma[j] = y.T.dot(R).dot(Kernel[j]).dot(R).dot(y)\n",
    "            S[j, p] = np.trace(V_inv.dot(Kernel[j]).dot(V_inv))  # last column\n",
    "            S[p, j] = S[j, p]\n",
    "            for k in range(j, p):\n",
    "                S[j, k] = np.trace(V_inv.dot(Kernel[j]).dot(V_inv).dot(Kernel[k]))\n",
    "                S[k, j] = S[j, k]\n",
    "\n",
    "        S[p, p] = np.trace(V_inv.dot(V_inv))\n",
    "        sigma[p] = y.T.dot(R).dot(R).dot(y)\n",
    "\n",
    "        sig_estimate = LA.inv(S).dot(sigma)\n",
    "        iteration_estimate.append(sig_estimate)\n",
    "\n",
    "        if verbose:\n",
    "            print_str = \"\\t MINQE(I) vanilla round \" + str(i) + \": \"\n",
    "            for j in range(p + 1):\n",
    "                print_str += \"  {:.4f}\".format(sig_estimate[j])\n",
    "            print(print_str, flush=True)\n",
    "\n",
    "        diff = np.max(np.abs(sig_estimate - prev_sig))\n",
    "        if diff < 1e-4:\n",
    "            exit_code = 0\n",
    "            if verbose:\n",
    "                print(\"\\t Estimates converged, exitting - diff: %.6f\" % (diff))\n",
    "            break\n",
    "\n",
    "    iteration_estimate = np.array(iteration_estimate)\n",
    "    return sig_estimate, iteration_estimate[0, :], iteration_estimate, exit_code\n",
    "\n",
    "\n",
    "# Original EM REML n x n formulation\n",
    "def reml_em(Kernel, X, y, sig_estimate=None, verbose=True, n_iter=10):\n",
    "    # Calculating new y\n",
    "    Q, R = LA.qr(X)\n",
    "    M = lambda O: O - Q @ (Q.T @ O)\n",
    "    resid = M(y)\n",
    "    y_new = (resid - resid.mean()) / resid.std(ddof=1)\n",
    "\n",
    "    n = Kernel[0].shape[0]\n",
    "    p = len(Kernel)\n",
    "    if sig_estimate is None:\n",
    "        sig_estimate = np.zeros(p + 1, dtype=np.float64)\n",
    "        sig_estimate[:] = np.var(y_new, ddof=1) / (p + 1)\n",
    "    iteration_estimate = []\n",
    "    # Convergence\n",
    "    exit_code = 1\n",
    "\n",
    "    for i in range(n_iter):\n",
    "        prev_sig = sig_estimate.copy()\n",
    "\n",
    "        V = sig_estimate[p] * np.eye(n, dtype=np.float64)  # for I\n",
    "        for j in range(p):\n",
    "            V += sig_estimate[j] * Kernel[j]\n",
    "\n",
    "        V_inv = LA.inv(V)\n",
    "        R = V_inv - V_inv.dot(X).dot(LA.inv(X.T.dot(V_inv).dot(X))).dot(X.T).dot(V_inv)\n",
    "\n",
    "        trace = np.zeros(p + 1, dtype=np.float64)\n",
    "        quad = np.zeros(p + 1, dtype=np.float64)\n",
    "        for j in range(p):\n",
    "            quad[j] = y_new.T.dot(R).dot(Kernel[j]).dot(R).dot(y_new)\n",
    "            trace[j] = np.trace(R.dot(Kernel[j]))\n",
    "\n",
    "        quad[p] = y_new.T.dot(R).dot(R).dot(y_new)\n",
    "        trace[p] = np.trace(R)\n",
    "\n",
    "        sig_estimate = prev_sig - ((prev_sig ** 2) * (trace - quad)) / n\n",
    "        iteration_estimate.append(sig_estimate)\n",
    "\n",
    "        print(\"Quad:\", quad)\n",
    "        print(\"Trace (RK):\", trace)\n",
    "\n",
    "        if verbose:\n",
    "            print_str = \"\\t EM REML vanilla round \" + str(i) + \": \"\n",
    "            for j in range(p + 1):\n",
    "                print_str += \"  {:.4f}\".format(sig_estimate[j])\n",
    "            print(print_str, flush=True)\n",
    "\n",
    "        diff = np.max(np.abs(sig_estimate - prev_sig))\n",
    "        if diff < 1e-4:\n",
    "            exit_code = 0\n",
    "            if verbose:\n",
    "                print(\"\\t Estimates converged, exitting - diff: %.6f\" % (diff))\n",
    "            break\n",
    "\n",
    "    iteration_estimate = np.array(iteration_estimate)\n",
    "    return sig_estimate, iteration_estimate[0, :], iteration_estimate, exit_code\n",
    "\n",
    "\n",
    "# Original EM ML n x n formulation\n",
    "def ml_em(Kernel, X, y, verbose=True, n_iter=10):\n",
    "    n = Kernel[0].shape[0]\n",
    "    p = len(Kernel)\n",
    "    sig_estimate = np.zeros(p + 1, dtype=np.float64)\n",
    "    sig_estimate[:] = np.var(y, ddof=1) / (p + 1)\n",
    "    iteration_estimate = []\n",
    "    # Convergence\n",
    "    exit_code = 1\n",
    "\n",
    "    for i in range(n_iter):\n",
    "        prev_sig = sig_estimate.copy()\n",
    "\n",
    "        V = sig_estimate[p] * np.eye(n, dtype=np.float64)  # for I\n",
    "        for j in range(p):\n",
    "            V += sig_estimate[j] * Kernel[j]\n",
    "\n",
    "        V_inv = LA.inv(V)\n",
    "        R = V_inv - V_inv.dot(X).dot(LA.inv(X.T.dot(V_inv).dot(X))).dot(X.T).dot(V_inv)\n",
    "\n",
    "        trace = np.zeros(p + 1, dtype=np.float64)\n",
    "        quad = np.zeros(p + 1, dtype=np.float64)\n",
    "        for j in range(p):\n",
    "            quad[j] = y.T.dot(R).dot(Kernel[j]).dot(R).dot(y)\n",
    "            trace[j] = np.trace(V_inv.dot(Kernel[j]))\n",
    "\n",
    "        quad[p] = y.T.dot(R).dot(R).dot(y)\n",
    "        trace[p] = np.trace(V_inv)\n",
    "\n",
    "        sig_estimate = prev_sig - ((prev_sig ** 2) * (trace - quad)) / n\n",
    "        iteration_estimate.append(sig_estimate)\n",
    "\n",
    "        if verbose:\n",
    "            print_str = \"\\t EM ML vanilla round \" + str(i) + \": \"\n",
    "            for j in range(p + 1):\n",
    "                print_str += \"  {:.4f}\".format(sig_estimate[j])\n",
    "            print(print_str, flush=True)\n",
    "\n",
    "        diff = np.max(np.abs(sig_estimate - prev_sig))\n",
    "        if diff < 1e-4:\n",
    "            exit_code = 0\n",
    "            if verbose:\n",
    "                print(\"\\t Estimates converged, exitting - diff: %.6f\" % (diff))\n",
    "            break\n",
    "\n",
    "    iteration_estimate = np.array(iteration_estimate)\n",
    "    return sig_estimate, iteration_estimate[0, :], iteration_estimate, exit_code\n",
    "\n",
    "\n",
    "# Original AI REML n x n formulation\n",
    "def reml_ai(Kernel, X, y, verbose=True, n_iter=10, starting_point=None):\n",
    "    n = Kernel[0].shape[0]\n",
    "    p = len(Kernel)\n",
    "    sig_estimate = np.zeros(p + 1, dtype=np.float64)\n",
    "    if starting_point is None:\n",
    "        sig_estimate[:] = np.var(y, ddof=1) / (p + 1)\n",
    "    else:\n",
    "        sig_estimate = starting_point.copy()\n",
    "    iteration_estimate = []\n",
    "    score_list = []\n",
    "    information_list = []\n",
    "    # Convergence\n",
    "    exit_code = 1\n",
    "\n",
    "    for i in range(n_iter):\n",
    "        prev_sig = sig_estimate.copy()\n",
    "\n",
    "        V = sig_estimate[p] * np.eye(n, dtype=np.float64)  # for I   ## DP: v = sigma_e * I\n",
    "        print(\"sig_estimate[-1]:\", sig_estimate[p])\n",
    "        for j in range(p):\n",
    "            print(\"sig_estimate[j]:\", sig_estimate[j])\n",
    "            V += sig_estimate[j] * Kernel[j]     ## DP: V = sigma*ZZ' + sigma_e * I\n",
    "        print(\"\\t\\tInverting covariance matrix\", flush=True)\n",
    "        V_inv = LA.inv(V)\n",
    "        print(\"\\t\\tCreating R matrix\", flush=True)\n",
    "        R = V_inv - V_inv.dot(X).dot(LA.inv(X.T.dot(V_inv).dot(X))).dot(X.T).dot(V_inv)\n",
    "\n",
    "        print(\"\\t\\tPopulating Information mat and Score vec\")\n",
    "        Information = np.zeros((p + 1, p + 1), dtype=np.float64)\n",
    "        score = np.zeros(p + 1, dtype=np.float64)\n",
    "        for j in range(p):\n",
    "            print(\"\\t\\t\\tRow: %d of %d\" % (j + 1, p), flush=True)\n",
    "            score[j] = np.trace(R.dot(Kernel[j])) - y.T.dot(R).dot(Kernel[j]).dot(R).dot(y)\n",
    "            Information[j, p] = y.T.dot(R).dot(Kernel[j]).dot(R).dot(R).dot(y)\n",
    "            Information[p, j] = Information[j, p]\n",
    "            for k in range(j, p):\n",
    "                Information[j, k] = y.T.dot(R).dot(Kernel[j]).dot(R).dot(Kernel[k]).dot(R).dot(y)\n",
    "                Information[k, j] = Information[j, k]\n",
    "\n",
    "        Information[p, p] = y.T.dot(R).dot(R).dot(R).dot(y)\n",
    "        Information = 0.5 * Information\n",
    "        score[p] = np.trace(R) - y.T.dot(R).dot(R).dot(y)\n",
    "        score = -0.5 * score\n",
    "        print(\"\\t\\tScore norm: %.6f, abs_max: %.6f\" % (LA.norm(score), np.abs(score).max()))\n",
    "        score_list.append(score)\n",
    "        information_list.append(Information)\n",
    "        print(\"\\t\\tSolving system linear system\")\n",
    "\n",
    "        delta = LA.inv(Information).dot(score)\n",
    "        sig_estimate = sig_estimate + delta\n",
    "        iteration_estimate.append(sig_estimate)\n",
    "\n",
    "        print(\"Information:\", Information)\n",
    "        print(\"Score:\", score)\n",
    "\n",
    "        if verbose:\n",
    "            print_str = \"\\t AI REML vanilla round \" + str(i) + \": \"\n",
    "            for j in range(p + 1):\n",
    "                print_str += \"  {:.4f}\".format(sig_estimate[j])\n",
    "            print(print_str, flush=True)\n",
    "\n",
    "        diff = np.max(np.abs(sig_estimate - prev_sig))\n",
    "        if diff < 1e-6:\n",
    "            exit_code = 0\n",
    "            if verbose:\n",
    "                print(\"\\t Estimates converged, existing - diff: %.6f\" % (diff))\n",
    "            break\n",
    "\n",
    "    iteration_estimate = np.array(iteration_estimate)\n",
    "    score_list = np.array(score_list)\n",
    "    information_list = np.array(information_list)\n",
    "    return sig_estimate, iteration_estimate[0, :], iteration_estimate, exit_code, score_list, information_list\n",
    "\n",
    "\n",
    "# Original AI ML n x n formulation\n",
    "def ml_ai(Kernel, X, y, verbose=True, n_iter=10):\n",
    "    n = Kernel[0].shape[0]\n",
    "    p = len(Kernel)\n",
    "    sig_estimate = np.zeros(p + 1, dtype=np.float64)\n",
    "    sig_estimate[:] = np.var(y, ddof=1) / (p + 1)\n",
    "    iteration_estimate = []\n",
    "    # Convergence\n",
    "    exit_code = 1\n",
    "\n",
    "    for i in range(n_iter):\n",
    "        prev_sig = sig_estimate.copy()\n",
    "\n",
    "        V = sig_estimate[p] * np.eye(n, dtype=np.float64)  # for I\n",
    "        for j in range(p):\n",
    "            V += sig_estimate[j] * Kernel[j]\n",
    "\n",
    "        V_inv = LA.inv(V)\n",
    "        R = V_inv - V_inv.dot(X).dot(LA.inv(X.T.dot(V_inv).dot(X))).dot(X.T).dot(V_inv)\n",
    "\n",
    "        Information = np.zeros((p + 1, p + 1), dtype=np.float64)\n",
    "        score = np.zeros(p + 1, dtype=np.float64)\n",
    "        for j in range(p):\n",
    "            score[j] = np.trace(V_inv.dot(Kernel[j])) - y.T.dot(R).dot(Kernel[j]).dot(R).dot(y)\n",
    "            Information[j, p] = y.T.dot(V_inv).dot(Kernel[j]).dot(V_inv).dot(V_inv).dot(y)\n",
    "            Information[p, j] = Information[j, p]\n",
    "            for k in range(j, p):\n",
    "                Information[j, k] = y.T.dot(V_inv).dot(Kernel[j]).dot(V_inv).dot(Kernel[k]).dot(V_inv).dot(y)\n",
    "                Information[k, j] = Information[j, k]\n",
    "\n",
    "        Information[p, p] = y.T.dot(V_inv).dot(V_inv).dot(V_inv).dot(y)\n",
    "        Information = 0.5 * Information\n",
    "        score[p] = np.trace(V_inv) - y.T.dot(R).dot(R).dot(y)\n",
    "        score = -0.5 * score\n",
    "\n",
    "        delta = LA.inv(Information).dot(score)\n",
    "        sig_estimate = sig_estimate + delta\n",
    "        iteration_estimate.append(sig_estimate)\n",
    "\n",
    "        if verbose:\n",
    "            print_str = \"\\t AI ML vanilla round \" + str(i) + \": \"\n",
    "            for j in range(p + 1):\n",
    "                print_str += \"  {:.4f}\".format(sig_estimate[j])\n",
    "            print(print_str, flush=True)\n",
    "\n",
    "        diff = np.max(np.abs(sig_estimate - prev_sig))\n",
    "        if diff < 1e-4:\n",
    "            exit_code = 0\n",
    "            if verbose:\n",
    "                print(\"\\t Estimates converged, exitting - diff: %.6f\" % (diff))\n",
    "            break\n",
    "\n",
    "    iteration_estimate = np.array(iteration_estimate)\n",
    "    return sig_estimate, iteration_estimate[0, :], iteration_estimate, exit_code\n",
    "\n",
    "\n",
    "# Original EI REML n x n formulation\n",
    "def reml_ei(Kernel, X, y, verbose=True, n_iter=10):\n",
    "    n = Kernel[0].shape[0]\n",
    "    p = len(Kernel)\n",
    "    sig_estimate = np.zeros(p + 1, dtype=np.float64)\n",
    "    sig_estimate[:] = np.var(y, ddof=1) / (p + 1)\n",
    "    iteration_estimate = []\n",
    "    # Convergence\n",
    "    exit_code = 1\n",
    "\n",
    "    for i in range(n_iter):\n",
    "        prev_sig = sig_estimate.copy()\n",
    "\n",
    "        V = sig_estimate[p] * np.eye(n, dtype=np.float64)  # for I\n",
    "        for j in range(p):\n",
    "            V += sig_estimate[j] * Kernel[j]\n",
    "\n",
    "        V_inv = LA.inv(V)\n",
    "        R = V_inv - V_inv.dot(X).dot(LA.inv(X.T.dot(V_inv).dot(X))).dot(X.T).dot(V_inv)\n",
    "\n",
    "        Information = np.zeros((p + 1, p + 1), dtype=np.float64)\n",
    "        score = np.zeros(p + 1, dtype=np.float64)\n",
    "        for j in range(p):\n",
    "            score[j] = np.trace(R.dot(Kernel[j])) - y.T.dot(R).dot(Kernel[j]).dot(R).dot(y)\n",
    "            Information[j, p] = np.trace(R.dot(Kernel[j]).dot(R))\n",
    "            Information[p, j] = Information[j, p]\n",
    "            for k in range(j, p):\n",
    "                Information[j, k] = np.trace(R.dot(Kernel[j]).dot(R).dot(Kernel[k]))\n",
    "                Information[k, j] = Information[j, k]\n",
    "\n",
    "        Information[p, p] = np.trace(R.dot(R))\n",
    "        Information = 0.5 * Information\n",
    "        score[p] = np.trace(R) - y.T.dot(R).dot(R).dot(y)\n",
    "        score = -0.5 * score\n",
    "\n",
    "        delta = LA.inv(Information).dot(score)\n",
    "        sig_estimate = sig_estimate + delta\n",
    "        iteration_estimate.append(sig_estimate)\n",
    "\n",
    "        print(\"Information:\", Information)\n",
    "        print(\"Score:\", score)\n",
    "\n",
    "        if verbose:\n",
    "            print_str = \"\\t EI REML vanilla round \" + str(i) + \": \"\n",
    "            for j in range(p + 1):\n",
    "                print_str += \"  {:.4f}\".format(sig_estimate[j])\n",
    "            print(print_str, flush=True)\n",
    "\n",
    "        diff = np.max(np.abs(sig_estimate - prev_sig))\n",
    "        if diff < 1e-4:\n",
    "            exit_code = 0\n",
    "            if verbose:\n",
    "                print(\"\\t Estimates converged, exitting - diff: %.6f\" % (diff))\n",
    "            break\n",
    "\n",
    "    iteration_estimate = np.array(iteration_estimate)\n",
    "    return sig_estimate, iteration_estimate[0, :], iteration_estimate, exit_code\n",
    "\n",
    "\n",
    "# Original EI ML n x n formulation\n",
    "def ml_ei(Kernel, X, y, verbose=True, n_iter=10):\n",
    "    n = Kernel[0].shape[0]\n",
    "    p = len(Kernel)\n",
    "    sig_estimate = np.zeros(p + 1, dtype=np.float64)\n",
    "    sig_estimate[:] = np.var(y, ddof=1) / (p + 1)\n",
    "    iteration_estimate = []\n",
    "    # Convergence\n",
    "    exit_code = 1\n",
    "\n",
    "    for i in range(n_iter):\n",
    "        prev_sig = sig_estimate.copy()\n",
    "\n",
    "        V = sig_estimate[p] * np.eye(n, dtype=np.float64)  # for I\n",
    "        for j in range(p):\n",
    "            V += sig_estimate[j] * Kernel[j]\n",
    "\n",
    "        V_inv = LA.inv(V)\n",
    "        R = V_inv - V_inv.dot(X).dot(LA.inv(X.T.dot(V_inv).dot(X))).dot(X.T).dot(V_inv)\n",
    "\n",
    "        Information = np.zeros((p + 1, p + 1), dtype=np.float64)\n",
    "        score = np.zeros(p + 1, dtype=np.float64)\n",
    "        for j in range(p):\n",
    "            score[j] = np.trace(V_inv.dot(Kernel[j])) - y.T.dot(R).dot(Kernel[j]).dot(R).dot(y)\n",
    "            Information[j, p] = np.trace(V_inv.dot(Kernel[j]).dot(V_inv))\n",
    "            Information[p, j] = Information[j, p]\n",
    "            for k in range(j, p):\n",
    "                Information[j, k] = np.trace(V_inv.dot(Kernel[j]).dot(V_inv).dot(Kernel[k]))\n",
    "                Information[k, j] = Information[j, k]\n",
    "\n",
    "        Information[p, p] = np.trace(V_inv.dot(V_inv))\n",
    "        Information = 0.5 * Information\n",
    "        score[p] = np.trace(V_inv) - y.T.dot(R).dot(R).dot(y)\n",
    "        score = -0.5 * score\n",
    "\n",
    "        delta = LA.inv(Information).dot(score)\n",
    "        sig_estimate = sig_estimate + delta\n",
    "        iteration_estimate.append(sig_estimate)\n",
    "\n",
    "        if verbose:\n",
    "            print_str = \"\\t EI ML vanilla round \" + str(i) + \": \"\n",
    "            for j in range(p + 1):\n",
    "                print_str += \"  {:.4f}\".format(sig_estimate[j])\n",
    "            print(print_str, flush=True)\n",
    "\n",
    "        diff = np.max(np.abs(sig_estimate - prev_sig))\n",
    "        if diff < 1e-4:\n",
    "            exit_code = 0\n",
    "            if verbose:\n",
    "                print(\"\\t Estimates converged, exitting - diff: %.6f\" % (diff))\n",
    "            break\n",
    "\n",
    "    iteration_estimate = np.array(iteration_estimate)\n",
    "    return sig_estimate, iteration_estimate[0, :], iteration_estimate, exit_code\n",
    "\n",
    "\n",
    "print('LMM was imported successfully.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
